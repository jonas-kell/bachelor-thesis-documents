@article{convNetForThe2020s,
  doi = {10.48550/ARXIV.2201.03545},
  url = {https://arxiv.org/abs/2201.03545},
  author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A ConvNet for the 2020s},
  publisher = {arXiv},
  year = {2022},  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{imageWorth16x16,
  doi = {10.48550/ARXIV.2010.11929},
  url = {https://arxiv.org/abs/2010.11929},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{attentionIsAllYouNeed,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{bertPaper,
  doi = {10.48550/ARXIV.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{channelNets,
  doi = {10.48550/ARXIV.1809.01330},
  url = {https://arxiv.org/abs/1809.01330},
  author = {Gao, Hongyang and Wang, Zhengyang and Ji, Shuiwang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{deepComplexNetworks,
  doi = {10.48550/ARXIV.1705.09792},
  url = {https://arxiv.org/abs/1705.09792},
  author = {Trabelsi, Chiheb and Bilaniuk, Olexa and Zhang, Ying and Serdyuk, Dmitriy and Subramanian, Sandeep and Santos, João Felipe and Mehri, Soroush and Rostamzadeh, Negar and Bengio, Yoshua and Pal, Christopher J},
  keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Complex Networks},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{deepResidualLearningForImageRecognition,
  doi = {10.48550/ARXIV.1512.03385},
  url = {https://arxiv.org/abs/1512.03385},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Residual Learning for Image Recognition},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{dinoPaper,
  doi = {10.48550/ARXIV.2104.14294},
  url = {https://arxiv.org/abs/2104.14294},
  author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Emerging Properties in Self-Supervised Vision Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{jVMCPaper,
  doi = {10.48550/ARXIV.2108.03409},
  url = {https://arxiv.org/abs/2108.03409},
  author = {Schmitt, Markus and Reh, Moritz},
  keywords = {Computational Physics (physics.comp-ph), Disordered Systems and Neural Networks (cond-mat.dis-nn), Strongly Correlated Electrons (cond-mat.str-el), FOS: Physical sciences, FOS: Physical sciences},
  title = {jVMC: Versatile and performant variational Monte Carlo leveraging automated differentiation and GPU acceleration},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{metaformerPaper,
  doi = {10.48550/ARXIV.2111.11418},
  url = {https://arxiv.org/abs/2111.11418},
  author = {Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MetaFormer Is Actually What You Need for Vision},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{mobileNetPaper,
  doi = {10.48550/ARXIV.1704.04861},
  url = {https://arxiv.org/abs/1704.04861},
  author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{relationalInductiveBiasesAndGraphNetworks,
  doi = {10.48550/ARXIV.1806.01261},
  url = {https://arxiv.org/abs/1806.01261},
  author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Relational inductive biases, deep learning, and graph networks},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{restrictedBoltzmanMachines,
  doi = {10.1038/s41567-019-0545-1},
  url = {https://doi.org/10.1038/s41567-019-0545-1},
  author = {Melko, Roger G. and Carleo, Giuseppe and Carrasquilla, Juan and Cirac, J. Ignacio},
  title = {Restricted Boltzmann machines in quantum physics},
  publisher = {Nature Physics},
  year = {2019},
}

@article{swinTransformerPaper,
  doi = {10.48550/ARXIV.2103.14030},
  url = {https://arxiv.org/abs/2103.14030},
  author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{quantumMBPwithneuralNetworks,
	doi = {10.1126/science.aag2302},
	url = {https://doi.org/10.1126%2Fscience.aag2302},
	year = 2017,
	month = {feb},
	publisher = {American Association for the Advancement of Science ({AAAS})},
	volume = {355},
	number = {6325},
	pages = {602--606},
	author = {Giuseppe Carleo and Matthias Troyer},
	title = {Solving the quantum many-body problem with artificial neural networks},
	journal = {Science}
}

@thesis{masterThesisKienzle,
  author  = {Daniel Kienzle},
  title   = {Neural Networks for Haldane-gap spin chains},
	year    = 2021,
}

@thesis{bachelorPatrikHopf,
  author  = {Patrick Heiko Hopf},
  title   = {Zeitliche Dynamik in Quantenbillards mit Hilfe neuronaler Netze},
	year    = 2021,
}

@online{jVMCgithub,
  author  = {Schmitt, Markus},
  title   = {jVMC},
  version = {1.1.2},
  url     = {https://github.com/markusschmitt/vmc_jax},
}

@online{cifarDataset,
  author  = {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
  title   = {The CIFAR-10 dataset},
  urldate = {2022-09-06},
  url     = {https://www.cs.toronto.edu/~kriz/cifar.html},
}

@incollection{pytorchGithub,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages = {8024--8035},
  year = {2019},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@online{jaxGithub,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@online{flaxGithub, 
  author = {Jonathan Heek and Anselm Levskaya and Avital Oliver and Marvin Ritter and Bertrand Rondepierre and Andreas Steiner and Marc van {Z}ee},
  title = {{F}lax: A neural network library and ecosystem for {JAX}},
  url = {http://github.com/google/flax},
  version = {0.6.0},
  year = {2020},
}

@online{dinoGithub,
  title={Emerging Properties in Self-Supervised Vision Transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\'egou, Herv\'e  and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the International Conference on Computer Vision (ICCV)},
  year={2021},
  url = {https://github.com/facebookresearch/dino},
  urldate = {2022-09-06},
}

@online{einopsGithub,
  title={Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation},
  author={Alex Rogozhnikov},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=oapKSVM2bcj}
}

@online{positionalEncodingGithub,
    title={1D, 2D, and 3D Sinusoidal Postional Encoding (Pytorch and Tensorflow)},
    author={Peter Tatkowski},
    year={2021},
    url = {https://github.com/tatp22/multidim-positional-encoding},
    urldate = {2022-09-06},
}

@online{poolformerGithub,
    title={PoolFormer: MetaFormer Is Actually What You Need for Vision (CVPR 2022 Oral)},
    author={Sea AI Lab},
    year={2021},
    url = {https://github.com/sail-sg/poolformer},
    urldate = {2022-09-06},
}

@article{arbirarySizedConvolution,
	url = {https://learnopencv.com/fully-convolutional-image-classification-on-arbitrary-sized-image/},
  urldate = {2022-09-06},
	year = 2020,
	publisher = {Learn Open CV},
	author = {Grigory Serebryakov and Satya Mallick},
	title = {Fully Convolutional Image Classification on Arbitrary Sized Image},
}

@online{symmetricConvolutionImplementation,
  title={CNN-Symmetry},
  author={Matthias Treder},
  year={2019},
  url = {https://github.com/treder/CNN-Symmetry},
  urldate = {2022-09-06},
}

@article{backpropagationInConvolutions,
	url = {https://pavisj.medium.com/convolutions-and-backpropagations-46026a8f5d2c},
  urldate = {2022-09-06},
	year = 2018,
	publisher = {Medium},
	author = {Pavithra Solai},
	title = {Convolutions and Backpropagations},
}

@article{separableConvolutions,
	url = {https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec},
  urldate = {2022-09-06},
	year = 2018,
	publisher = {Medium},
	author = {Atul Pandey},
	title = {Depth-wise Convolution and Depth-wise Separable Convolution},
}

@online{hexagonalGrids,
  title={Hexagonal Grids},
  author={Amit Patel},
  year={2013},
  url = {https://www.redblobgames.com/grids/hexagons/},
  urldate = {2022-09-06},
}

@online{selfDocuments,
  title={Investigation of transformer architectures for geometrical graph structures and their application to two dimensional spin systems},
  author={Jonas Kell},
  year={2022},
  url = {https://github.com/jonas-kell/bachelor-thesis-documents},
}

@online{selfPhysics,
  title={Physis-Part implementation and Code Reference},
  author={Jonas Kell},
  year={2022},
  url = {https://github.com/jonas-kell/bachelor-thesis-code},
}

@online{selfComputerScience,
  title={Computer-Science-Part implementation and Code Reference},
  author={Jonas Kell},
  year={2022},
  url = {https://github.com/jonas-kell/bachelor-thesis-experiments},
}