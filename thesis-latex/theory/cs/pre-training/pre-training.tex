% TODO 
% - Theoretical use of pre-training
% - Unsupervised Training 
% - General knowledge destillation
% - Refining more efficient than learning from scratch 


% SOURCE: \cite{imageWorth16x16}
% - pre-training very important. Cite, and explain why not used here 

% SOURCE: \cite{bertPaper}
% - pre-training by covering up words and letting them be reconstructed.

% SOURCE: \cite{dinoPaper}
% - Self supervised clustering as Pre-training 
% - knowledge destillation with teacher-pupil networks complementary